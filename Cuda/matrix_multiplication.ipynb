{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a36747",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile matrixMult.cu\n",
    "\n",
    "#include <bits/stdc++.h>\n",
    "#include <cuda.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "__global__ void matrixMultKernel(float* A, float* B, float* C, int M, int N, int P, int matricePosition) {\n",
    "\n",
    "    int k = threadIdx.x + matricePosition;\n",
    "\n",
    "    float* a = A + k * M * N;\n",
    "    float* b = B + k * N * P;\n",
    "    float* c = C + k * M * P;\n",
    "\n",
    "    for(int i = 0; i < M; i++) {\n",
    "        for(int j = 0; j < N; j++) {\n",
    "            for(int l = 0; l < P; l++) {\n",
    "                c[i * P + l] += a[i * N + j] * b[j * P + l];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "\n",
    "    int T = atoi(argv[1]); // Number of threads\n",
    "    int K = atoi(argv[2]); // Number of matrices\n",
    "\n",
    "    //int M = 5, N = 5, P = 5; // Dimensions of the matrices\n",
    "\n",
    "    int M = atoi(argv[3]);\n",
    "    int N = atoi(argv[4]);\n",
    "    int P = atoi(argv[5]);\n",
    "\n",
    "    int sizeA = M * N * K;\n",
    "    int sizeB = N * P * K;\n",
    "    int sizeC = M * P * K;\n",
    "\n",
    "    // Allocate memory to CPU\n",
    "    float *h_A = new float[sizeA];\n",
    "    float *h_B = new float[sizeB];\n",
    "    float *h_C = new float[sizeC];\n",
    "\n",
    "    // Initialize matrices A and B\n",
    "    for (int i = 0; i < sizeA; i++) {\n",
    "        h_A[i] = rand() % 10;\n",
    "    }\n",
    "    for(int i = 0; i < sizeB; i++) {\n",
    "        h_B[i] = rand() % 10;\n",
    "    }\n",
    "\n",
    "    // Allocate memory to GPU\n",
    "    float *d_A;\n",
    "    cudaMalloc(&d_A, sizeA * sizeof(float));\n",
    "    float *d_B;\n",
    "    cudaMalloc(&d_B, sizeB * sizeof(float));\n",
    "    float *d_C;\n",
    "    cudaMalloc(&d_C, sizeC * sizeof(float));\n",
    "\n",
    "\n",
    "\n",
    "    //copy from host to device\n",
    "    cudaMemcpy(d_A, h_A, sizeA * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, sizeB * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    //cuda process suru\n",
    "    int matricesLeftForMult = K;\n",
    "    int matricePosition = 0;\n",
    "\n",
    "    while(matricesLeftForMult > 0){\n",
    "\n",
    "        int currentBatch = min(matricesLeftForMult, T);\n",
    "\n",
    "        // kernel_name <<< numBlocks, threadsPerBlock >>> (kernel_arguments...);\n",
    "\n",
    "        matrixMultKernel <<<1, currentBatch>>> (d_A, d_B, d_C, M, N, P, matricePosition);\n",
    "        cudaDeviceSynchronize();\n",
    "\n",
    "        matricesLeftForMult -= currentBatch;\n",
    "        matricePosition += currentBatch;\n",
    "    }\n",
    "\n",
    "\n",
    "    // copy back to cpu\n",
    "    cudaMemcpy(h_C, d_C, sizeC * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "\n",
    "    // Print result matrix C for each batch\n",
    "    for (int k = 0; k < K; ++k) {\n",
    "        cout << \"Matrix C[\" << k << \"]:\" << endl;\n",
    "        for (int i = 0; i < M; ++i) {\n",
    "            for (int j = 0; j < P; ++j) {\n",
    "                cout << h_C[k * M * P + i * P + j] << \" \";\n",
    "            }\n",
    "            cout << endl;\n",
    "        }\n",
    "        cout << \"-----------------------------\" << endl;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Free GPU memory\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "\n",
    "    // Free CPU memory\n",
    "    delete[] h_A;\n",
    "    delete[] h_B;\n",
    "    delete[] h_C;\n",
    "\n",
    "\n",
    "    cout << \"All operation done\" << endl;\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
